# 基本概念
## 介绍
spark的有两个机器学习库ml和mllib。
ml库底层数据结构是DataFrame，mllib底层数据结构是RDD。

DataFrame的概念更符合数据挖掘工程师的使用习惯（pandas也是DataFrame)。


## LabeledPoint
```
case class LabeledPoint(@Since("2.0.0") label: Double, @Since("2.0.0") features: Vector) {
  override def toString: String = {
    s"($label,$features)"
  }
}
```
LabeledPoint用于分类场景，label即分类的类别。features为特征


## DenseVector

```
class DenseVector @Since("2.0.0") ( @Since("2.0.0") val values: Array[Double]) extends Vector {

  override def size: Int = values.length

  override def toString: String = values.mkString("[", ",", "]")

  override def toArray: Array[Double] = values

  private[spark] override def asBreeze: BV[Double] = new BDV[Double](values)

  override def apply(i: Int): Double = values(i)

```
顾名思义，存储稠密向量。

## SparseVector
```
/**
 * A sparse vector represented by an index array and a value array.
 *
 * @param size size of the vector.
 * @param indices index array, assume to be strictly increasing.
 * @param values value array, must have the same length as the index array.
 */
@Since("2.0.0")
class SparseVector @Since("2.0.0") (
    override val size: Int,
    @Since("2.0.0") val indices: Array[Int],
    @Since("2.0.0") val values: Array[Double]) extends Vector
```

SparseVector的存储结构和DenseVector不同。
DenseVector用的数组。SparseVector存的索引和值，没有值的就不存储了,在向量非常稀疏的时候非常节省存储空间。

