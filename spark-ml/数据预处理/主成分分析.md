# PCA
示例：
```
    // $example on$
    val data = Array(
      Vectors.sparse(5, Seq((1, 1.0), (3, 7.0))),
      Vectors.dense(2.0, 0.0, 3.0, 4.0, 5.0),
      Vectors.dense(4.0, 0.0, 0.0, 6.0, 7.0)
    )
    val df = spark.createDataFrame(data.map(Tuple1.apply)).toDF("features")

    val pca = new PCA()
      .setInputCol("features")
      .setOutputCol("pcaFeatures")
      .setK(3)
      .fit(df)

    val result = pca.transform(df).select("pcaFeatures")
```
使用很简单，指定输入特征，输出特征名称，降维后的维数。

内部调用RowMatrix的computePrincipalComponentsAndExplainedVariance方法计算主成分。
```
    val (pc, explainedVariance) = mat.computePrincipalComponentsAndExplainedVariance(k)

```

具体计算过程为：

1. 计算X的协方差矩阵Σ；
2. 对协方差矩阵进行SVD奇异值分解；
3. 选择左奇异矩阵的前n*k个值作为降维的结果；

保留最上面的k个特征向量
```
    val Cov = computeCovariance().asBreeze.asInstanceOf[BDM[Double]]

    val brzSvd.SVD(u: BDM[Double], s: BDV[Double], _) = brzSvd(Cov)

    val eigenSum = s.data.sum
    val explainedVariance = s.data.map(_ / eigenSum)

    if (k == n) {
      (Matrices.dense(n, k, u.data), Vectors.dense(explainedVariance))
    } else {
      (Matrices.dense(n, k, Arrays.copyOfRange(u.data, 0, n * k)),
        Vectors.dense(Arrays.copyOfRange(explainedVariance, 0, k)))
    }

```

